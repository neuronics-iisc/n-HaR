<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
<title>NeuRonICS</title>
<meta charset="UTF-8">
<link rel="stylesheet" href="styles/layout.css" type="text/css">
<!--[if lt IE 9]><script src="scripts/html5shiv.js"></script><![endif]-->
<style>
.center {
  text-align: center;
  border: 3px solid green;
}
.marg {
  margin-right: 150px;
 }

</style>
</head>
<body>
<div class="wrapper row1">
  <header id="header" class="clear">
    <div id="hgroup">
      <h1><a href="#">NeuRonICS Dataset Repository</a></h1>
      <!--<h2>Free HTML5 Website Template</h2>-->
    </div>
    <!--<nav>
      <ul>
        <li><a href="#">Text Link</a></li>
        <li><a href="#">Text Link</a></li>
        <li><a href="#">Text Link</a></li>
        <li><a href="#">Text Link</a></li>
        <li class="last"><a href="#">Text Link</a></li>
      </ul>
    </nav> -->
  </header>
  <div class="center">
</div>
 <div class="navbar">
  

  </div>
    
  </div>
</div> 
</div>
<!-- content -->

<div class="wrapper row2">
  <div id="container" class="clear">
    <!-- Slider -->
    

      <h2><a href="#">N-Har Dataset [Neuromorphic Human activity Recognition]</a></h2>

      <div id="homepage">
      <p style="font-size:150%;" style="color:black;"; style="text-align:justify">Though the conventional frame-based cameras have advanced in a lot of ways, they suffer from data redundancy and temporal latency. The bio-inspired artificial retinas eliminate the data redundancy by capturing only the change in illumination at each pixel and asynchronously communicating in binary spikes. In this work, we propose a system to achieve the task of human activity recognition based on the event-based camera data. We show that such tasks, which generally need high frame rate sensors for accurate predictions, can be achieved by adapting existing computer vision techniques to the spiking domain. We used event memory surfaces to make the sparse event data compatible with deep convolutional neural networks (CNNs). We leverage upon the recent advances in deep convolutional networks based video analysis and adapt such frameworks onto the neuromorphic domain. We also provide the community with a new dataset consisting of five categories of human activities captured in real-world without any simulations. We achieved an accuracy of94.3% using event memory surfaces on our activity recognition dataset.</p>
      <p style="font-size:150%;">The research can be found here <a href="https://ieeexplore.ieee.org/document/8702581">paper</a> </p>
      <b> <p style="font-size:150%;">Sample Imags</p> </b>
    <figure><img src="images/n-har.png" alt="" height="350" width="450" hspace="20">
    <br>
    <br>

    <h3>Instructions to download</h3>
    <p style="font-size:150%;">Since the dataset is huge, hence we can only provide private access to individual keys. 
Please mail us at "neuronicslab@iisc.ac.in" for the access</p>










    
 




























    <!-- right column -->
   
    <!-- / content body -->
  </div>
</div>
<!-- Footer -->
<div class="wrapper row3">
  <footer id="footer" class="clear">
    <p class="fl_left">Copyright &copy; 2018 - All Rights Reserved - <p>Indian Institute of Science</p></p>
   
  </footer>
</div>
</body>
</html>

